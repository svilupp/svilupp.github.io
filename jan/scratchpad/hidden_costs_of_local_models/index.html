<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <!-- bootstrap@5.3.1 and bootstrap icon@1.10--> <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel=stylesheet  integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin=anonymous > <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css"> <link rel=stylesheet  href="/css/style.css"> <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/@docsearch/css@3"> <link data-n-head=ssr  rel=stylesheet  href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700,900|Material+Icons"> <link rel=stylesheet  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin=anonymous  referrerpolicy=no-referrer  /> <link rel=stylesheet  href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha512-NhSC1YmyruXifcj/KFRWoC561YpHpc5Jtzgvbuzx5VozKpWvQ+4nXhPdFgmx8xqexRcpAglTj9sIBWINXa8x5w==" crossorigin=anonymous  referrerpolicy=no-referrer  /> <!-- favicon generated through https://realfavicongenerator.net/--> <link rel=apple-touch-icon  sizes=180x180  href="/assets/icon/apple-touch-icon.png"> <link rel=icon  type="image/png" sizes=32x32  href="/assets/icon/favicon-32x32.png"> <link rel=icon  type="image/png" sizes=16x16  href="/assets/icon/favicon-16x16.png"> <link rel=manifest  href="/assets/icon/site.webmanifest"> <link rel=mask-icon  href="/assets/icon/safari-pinned-tab.svg" color="#5bbad5"> <meta name=msapplication-TileColor  content="#da532c"> <meta name=theme-color  content="#ffffff"> <link rel=stylesheet  href="/_css/custom.css"> <title>The Hidden Cost of locally hosted Models: A Case Study</title> <header data-bs-theme=dark > <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"> <div class=container > <a href="/" class="navbar-brand d-flex align-items-center"> <svg xmlns="http://www.w3.org/2000/svg" width=16  height=16  fill=currentColor  class="bi bi-journal-text me-2" viewBox="0 0 16 16"> <path d="M5 10.5a.5.5 0 0 1 .5-.5h2a.5.5 0 0 1 0 1h-2a.5.5 0 0 1-.5-.5zm0-2a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5zm0-2a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5zm0-2a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5z"/> <path d="M3 0h10a2 2 0 0 1 2 2v12a2 2 0 0 1-2 2H3a2 2 0 0 1-2-2v-1h1v1a1 1 0 0 0 1 1h10a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1H3a1 1 0 0 0-1 1v1H1V2a2 2 0 0 1 2-2z"/> <path d="M1 5v-.5a.5.5 0 0 1 1 0V5h.5a.5.5 0 0 1 0 1h-2a.5.5 0 0 1 0-1H1zm0 3v-.5a.5.5 0 0 1 1 0V8h.5a.5.5 0 0 1 0 1h-2a.5.5 0 0 1 0-1H1zm0 3v-.5a.5.5 0 0 1 1 0v.5h.5a.5.5 0 0 1 0 1h-2a.5.5 0 0 1 0-1H1z"/> </svg> <strong>siml.earth</strong> </a> <button class=navbar-toggler  type=button  data-bs-toggle=collapse  data-bs-target="#navbarCollapse" aria-controls=navbarCollapse  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarCollapse > <ul class="navbar-nav me-auto mb-2 mb-md-0"> <li class="nav-item dropdown"> <a class="nav-link dropdown-toggle fw-bold" href="#" id=navbarDropdown  role=button  data-bs-toggle=dropdown  aria-expanded=false > Sites </a> <ul class=dropdown-menu  aria-labelledby=navbarDropdown > <li><h6 class=dropdown-header >Choose a Site</h6> <li><a class=dropdown-item  href="/jan/">Jan's Site</a> <li><a class=dropdown-item  href="/ann/">Ann's Site</a> </ul> <li class=nav-item ><hr class="dropdown-divider mx-2"> <li class=nav-item > <span class="navbar-text px-2 fw-bold d-flex align-items-center">Jan's:</span> <li class=nav-item > <a class=nav-link  aria-current=page  href="/jan/">Home</a> <li class=nav-item > <a class=nav-link  href="/jan/scratchpad/">Posts</a> <li class=nav-item > <a class=nav-link  href="/jan/wip/">Work in Progress</a> <li class=nav-item > <a class=nav-link  href="/jan/about/">About</a> <li class=nav-item > <a class=nav-link  href="/jan/tags/">Tags</a> <li class=nav-item > <a class=nav-link  href="/jan/privacy_policy/">Privacy Policy</a> <li class=nav-item > <a class=nav-link  href="/jan/cookie_policy/">Cookie Policy</a> </ul> </div> </div> </nav> </header> <div class="container py-3 px-3 mx-auto"> <div class=franklin-content ><h1 id=tldr ><a href="#tldr" class=header-anchor >TL;DR</a></h1> <p>locally hosted AI models may appear free, but they cost you valuable time—over 10 hours a year in our case study. Switch to a commercial API like Groq to save time, boost productivity, and gain nearly three extra days of coding annually for a dollar&#33;</p> <div class=franklin-toc ><ol><li><a href="#tldr">TL;DR</a><ol><li><a href="#would_you_pay_a_dollar_to_buy_3_extra_days_this_year">Would You Pay a Dollar to Buy 3 Extra Days This Year?</a><li><a href="#appreciating_the_open-source_ai_ecosystem">Appreciating the Open-Source AI Ecosystem</a><li><a href="#the_hidden_costs_of_local_hosting">The Hidden Costs of Local Hosting</a><ol><li><a href="#case_study_daily_coding_assistance">Case Study: Daily Coding Assistance</a></ol><li><a href="#why_choose_cloud_providers">Why Choose Cloud Providers?</a><li><a href="#how_to_start">How to Start?</a><ol><li><a href="#example_usage">Example Usage</a></ol><li><a href="#in_conclusion">In Conclusion</a><li><a href="#appendix">Appendix</a></ol></ol></div> <h2 id=would_you_pay_a_dollar_to_buy_3_extra_days_this_year ><a href="#would_you_pay_a_dollar_to_buy_3_extra_days_this_year" class=header-anchor >Would You Pay a Dollar to Buy 3 Extra Days This Year?</a></h2> <p>Imagine you could buy time. Not in a metaphorical sense, but literally reclaim hours of your life lost to waiting. For those of us using locally hosted models for ad-hoc productivity tasks like coding assistance, this isn&#39;t just a daydream—it&#39;s a decision we face every day.</p> <h2 id=appreciating_the_open-source_ai_ecosystem ><a href="#appreciating_the_open-source_ai_ecosystem" class=header-anchor >Appreciating the Open-Source AI Ecosystem</a></h2> <p>First, let&#39;s give credit where it&#39;s due. The thriving open-source ecosystem in generative AI deserves a massive shoutout. Organizations like Meta and Mistral have opened up their models, and platforms like Ollama and Llama.cpp have made these tools accessible for local use. This democratization of technology is nothing short of revolutionary. However, it&#39;s crucial to discuss the true cost of operating these technologies locally &#40;by individuals, for ad-hoc tasks&#41;.</p> <h2 id=the_hidden_costs_of_local_hosting ><a href="#the_hidden_costs_of_local_hosting" class=header-anchor >The Hidden Costs of Local Hosting</a></h2> <p>While the price tag on locally hosted models might read &quot;free,&quot; the reality is anything but. These models often underperform compared to their cloud-hosted counterparts &#40;GPU-poor&#41; or make you wait longer—sometimes both. For example, using a locally hosted model like Mixtral on Ollama, you might wait 20 seconds for a response that a commercial provider like Groq, Together, etc. could deliver in less than a second.</p> <h3 id=case_study_daily_coding_assistance ><a href="#case_study_daily_coding_assistance" class=header-anchor >Case Study: Daily Coding Assistance</a></h3> <p>Let&#39;s break it down with a simple case study. Assume you&#39;re a developer making three LLM calls per hour during a three-hour coding session, each day for 250 days a year. That&#39;s 2250 LLM calls.</p> <p>With Ollama, a 20-second wait per call accumulates to over 12 hours spent just waiting annually. </p> <p>In contrast, using Groq&#39;s API, even with an extremely conservative 3-second wait &#40;Llama 3 70b, which is GPT-4 level model&#41;, you&#39;d spend less than 2 hours waiting over the same period.</p> <p>The difference? <strong>More than 10 hours</strong> saved—or, put another way, over 3 extra days of productive coding time each year. </p> <p>And the cost of this extra time? Right now - FREE&#33; Assuming the announced pricing, <strong>about &#36;1.5</strong>.</p> <p>Moreover, with Groq, we assumed using GPT-4 level model&#33; So you would likely benefit even more from MUCH better answers&#33;</p> <h2 id=why_choose_cloud_providers ><a href="#why_choose_cloud_providers" class=header-anchor >Why Choose Cloud Providers?</a></h2> <p>Given <strong>you have roughly 4,000 weeks on this earth</strong>, spending any of them waiting on your GPU seems like a poor use of time. In a way, time is the scarcest resource yet you throw it away to save fractions of cents.</p> <p>Furthermore, you might lose out on innovations. Cloud providers continually upgrade their services with faster and more powerful models without requiring any effort on your part. Meanwhile, changing your local setup is a significant investment and it has its limits &#40;VRAM...&#41;.</p> <h2 id=how_to_start ><a href="#how_to_start" class=header-anchor >How to Start?</a></h2> <p>Switching is simple:</p> <ol> <li><p>Sign up for the <a href="https://console.groq.com/keys">Groq API</a>.</p> <li><p>Set up your environment variable <code>GROQ_API_KEY</code>.</p> <li><p>Use PromptingTools.jl with a Groq-hosted Llama3 70b, which I aliased with &quot;gl70&quot; &#40;Groq Llama 70&#41;. This alias helps save time even when typing&#33;</p> </ol> <h3 id=example_usage ><a href="#example_usage" class=header-anchor >Example Usage</a></h3> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> PromptingTools
<span class=hljs-comment ># Assumes you have set the environment variable GROQ_API_KEY</span>

<span class=hljs-string >ai&quot;In Julia, write a function `clean_names` that cleans up column names of a DataFrame&quot;gl70</span></code></pre> <pre><code class="plaintext hljs">[ Info: Tokens: 411 @ Cost: \$0.0003 in 2.7 seconds
AIMessage(&quot;Here is a Julia function `clean_names` that cleans up column names of a DataFrame:
```julia
using DataFrames
&lt;...continues&gt;
```</code></pre> <p>This simple setup can drastically cut down your waiting time, freeing up days for you to spend on more fulfilling activities or further innovation.</p> <p>If you&#39;re familiar with the <a href="https://github.com/svilupp/PromptingTools.jl">PromptingTools.jl</a> package, you know you can even set up an auto-fixing loop that will execute the generated code, analyze the error for feedback and retry automatically to fix any errors with Monte Carlo Tree Search &#40;see <code>?airetry&#33;</code> for more details&#41;.</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> PromptingTools.Experimental.AgentTools: AIGenerate, run!, AICode
<span class=hljs-keyword >using</span> PromptingTools.Experimental.AgentTools: airetry!, aicodefixer_feedback

result = AIGenerate(
    <span class=hljs-string >&quot;In Julia, write a function `clean_names` that cleans up column names of a DataFrame&quot;</span>;
    model = <span class=hljs-string >&quot;gl70&quot;</span>) |&gt; run!
aicodefixer_feedback
success_func(aicall) = AICode(aicall) |&gt; isvalid
feedback_func(aicall) = aicodefixer_feedback(aicall.conversation).feedback
airetry!(success_func, result, feedback_func; max_retries = <span class=hljs-number >3</span>)</code></pre> <h2 id=in_conclusion ><a href="#in_conclusion" class=header-anchor >In Conclusion</a></h2> <p>While the allure of &quot;free&quot; local hosting is strong, the hidden costs in time can be substantial. By opting for a commercial solution like Groq&#39;s API, not only do you reclaim time lost to waiting, but you also benefit from superior model performance. The investment is minimal compared to the time you buy back—time that could be spent innovating, creating, or just enjoying life. Isn&#39;t that worth considering?</p> <p>If you&#39;re looking to try, do it now while Groq is free&#33;&#33; <a href="https://console.groq.com/keys">Get your API key here</a>.</p> <h2 id=appendix ><a href="#appendix" class=header-anchor >Appendix</a></h2> <p>I made a claim that Llama 3 70b is a GPT-4 level model, check out our Leaderboard <a href="https://siml.earth/Julia-LLM-Leaderboard/dev/examples/summarize_results_local/#Model-Comparison">here</a> to see the results in an out-of-sample benchmark.</p> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Jan Siml. Last modified: November 17, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div></div> <footer class=container > <p class=float-end ><a href="#">Back to top</a></p> <div class=footer-icons > <ul class=social-icons > <li><strong>Follow:</strong> <li><a href="https://github.com/svilupp" rel="nofollow noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width=16  height=16  fill=currentColor  class="bi bi-github" viewBox="0 0 16 16"> <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/> </svg> GitHub</a> </ul> </div> <p class=copyright >&copy; 2023- Company, Inc. · <a href="#">Privacy</a> · <a href="#">Terms</a></p> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js" integrity=sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm  crossorigin=anonymous ></script> <script src="/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script> <script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>