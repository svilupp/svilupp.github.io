<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <!-- bootstrap@5.3.1 and bootstrap icon@1.10--> <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel=stylesheet  integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin=anonymous > <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css"> <link rel=stylesheet  href="/css/style.css"> <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/@docsearch/css@3"> <link data-n-head=ssr  rel=stylesheet  href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700,900|Material+Icons"> <link rel=stylesheet  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin=anonymous  referrerpolicy=no-referrer  /> <link rel=stylesheet  href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha512-NhSC1YmyruXifcj/KFRWoC561YpHpc5Jtzgvbuzx5VozKpWvQ+4nXhPdFgmx8xqexRcpAglTj9sIBWINXa8x5w==" crossorigin=anonymous  referrerpolicy=no-referrer  /> <!-- favicon generated through https://realfavicongenerator.net/--> <link rel=apple-touch-icon  sizes=180x180  href="/assets/icon/apple-touch-icon.png"> <link rel=icon  type="image/png" sizes=32x32  href="/assets/icon/favicon-32x32.png"> <link rel=icon  type="image/png" sizes=16x16  href="/assets/icon/favicon-16x16.png"> <link rel=manifest  href="/assets/icon/site.webmanifest"> <link rel=mask-icon  href="/assets/icon/safari-pinned-tab.svg" color="#5bbad5"> <meta name=msapplication-TileColor  content="#da532c"> <meta name=theme-color  content="#ffffff"> <link rel=stylesheet  href="/_css/custom.css"> <title>Running a 70 Billion-Parameter LLM on Your Laptop?</title> <header data-bs-theme=dark > <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"> <div class=container > <a href="/" class="navbar-brand d-flex align-items-center"> <svg xmlns="http://www.w3.org/2000/svg" width=16  height=16  fill=currentColor  class="bi bi-journal-text me-2" viewBox="0 0 16 16"> <path d="M5 10.5a.5.5 0 0 1 .5-.5h2a.5.5 0 0 1 0 1h-2a.5.5 0 0 1-.5-.5zm0-2a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5zm0-2a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5zm0-2a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5z"/> <path d="M3 0h10a2 2 0 0 1 2 2v12a2 2 0 0 1-2 2H3a2 2 0 0 1-2-2v-1h1v1a1 1 0 0 0 1 1h10a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1H3a1 1 0 0 0-1 1v1H1V2a2 2 0 0 1 2-2z"/> <path d="M1 5v-.5a.5.5 0 0 1 1 0V5h.5a.5.5 0 0 1 0 1h-2a.5.5 0 0 1 0-1H1zm0 3v-.5a.5.5 0 0 1 1 0V8h.5a.5.5 0 0 1 0 1h-2a.5.5 0 0 1 0-1H1zm0 3v-.5a.5.5 0 0 1 1 0v.5h.5a.5.5 0 0 1 0 1h-2a.5.5 0 0 1 0-1H1z"/> </svg> <strong>siml.earth</strong> </a> <button class=navbar-toggler  type=button  data-bs-toggle=collapse  data-bs-target="#navbarCollapse" aria-controls=navbarCollapse  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarCollapse > <ul class="navbar-nav me-auto mb-2 mb-md-0"> <li class="nav-item dropdown"> <a class="nav-link dropdown-toggle fw-bold" href="#" id=navbarDropdown  role=button  data-bs-toggle=dropdown  aria-expanded=false > Sites </a> <ul class=dropdown-menu  aria-labelledby=navbarDropdown > <li><h6 class=dropdown-header >Choose a Site</h6> <li><a class=dropdown-item  href="/jan/">Jan's Site</a> <li><a class=dropdown-item  href="/ann/">Ann's Site</a> </ul> <li class=nav-item ><hr class="dropdown-divider mx-2"> <li class=nav-item > <span class="navbar-text px-2 fw-bold d-flex align-items-center">Jan's:</span> <li class=nav-item > <a class=nav-link  aria-current=page  href="/jan/">Home</a> <li class=nav-item > <a class=nav-link  href="/jan/scratchpad/">Posts</a> <li class=nav-item > <a class=nav-link  href="/jan/wip/">Work in Progress</a> <li class=nav-item > <a class=nav-link  href="/jan/about/">About</a> <li class=nav-item > <a class=nav-link  href="/jan/tags/">Tags</a> <li class=nav-item > <a class=nav-link  href="/jan/privacy_policy/">Privacy Policy</a> <li class=nav-item > <a class=nav-link  href="/jan/cookie_policy/">Cookie Policy</a> </ul> </div> </div> </nav> </header> <div class="container py-3 px-3 mx-auto"> <div class=franklin-content ><h1 id=tldr ><a href="#tldr" class=header-anchor >TL;DR</a></h1> <p>You can now run the 70 billion parameter Llama2 language model locally on an M1 Mac in Julia &#40;thanks to llama.cpp 2-bit quantization&#41;</p> <p><div class=franklin-toc ><ol><li><a href="#tldr">TL;DR</a><ol><li><a href="#running_a_70_billion-parameter_llm_on_your_laptop">Running a 70 Billion-Parameter LLM on Your Laptop?</a><li><a href="#llamajl_to_the_rescue">Llama.jl to the rescue&#33;</a><li><a href="#try_the_rocket_model">Try the Rocket model</a><li><a href="#conclusion">Conclusion</a></ol></ol></div> </p> <h2 id=running_a_70_billion-parameter_llm_on_your_laptop ><a href="#running_a_70_billion-parameter_llm_on_your_laptop" class=header-anchor >Running a 70 Billion-Parameter LLM on Your Laptop?</a></h2> <p>It&#39;s a fascinating time in the world of generative AI and large language models. I recently had an experience that seemed almost surreal just a year ago—I ran a 70 billion parameter language model, Llama2, locally on my Mac M1. To put that into perspective, if each parameter were an M&amp;M, we could fill more than 10 Olympic-sized swimming pools&#33;</p> <p>What made this possible is the recent release of Llama.cpp, supporting new 2-bit quantization. This practically compresses the model to use almost 16 times less memory compared to traditional Float32 parameters. It&#39;s an incredible leap in model efficiency and accessibility. It&#39;s not without &quot;price&quot;, but its performance is still impressive.</p> <h2 id=llamajl_to_the_rescue ><a href="#llamajl_to_the_rescue" class=header-anchor >Llama.jl to the rescue&#33;</a></h2> <p>For those eager to try this out, the Julia programming community has made it incredibly easy. Recently, I discovered a nifty package <a href="https://github.com/marcom/Llama.jl">Llama.jl</a>, which wraps the famous llama.cpp, but you don&#39;t have to compile anything&#33; Julia&#39;s Artifact ecosystem streamlines the process.</p> <p>Here’s how you can do it:</p> <pre><code class="julia hljs"><span class=hljs-comment ># Install the package first</span>
<span class=hljs-keyword >using</span> Pkg; Pkg.add(<span class=hljs-string >&quot;https://github.com/marcom/Llama.jl&quot;</span>)

<span class=hljs-keyword >using</span> Llama

<span class=hljs-comment ># Go make a cup of tea while you wait... this is a 20GB download!</span>
url = <span class=hljs-string >&quot;https://huggingface.co/ikawrakow/various-2bit-sota-gguf/resolve/main/llama-v2-70b-2.12bpw.gguf&quot;</span>
model = download_model(url) 

<span class=hljs-comment ># and now we can run the server:</span>
Llama.run_server(; model)
<span class=hljs-comment ># Note: If you get some memory or GPU problems, look at parameter `n_gpu_layers`, which dictates how many layers of your model should go onto your GPU vs CPU</span></code></pre> <p>To try it out either open http://127.0.0.1:10897 in your browser or use PromptingTools.jl like you would with any OpenAI-compatible server:</p> <p>Open a separate Julia session and run:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> PromptingTools
<span class=hljs-keyword >const</span> PT = PromptingTools

msg = aigenerate(PT.CustomOpenAISchema(), <span class=hljs-string >&quot;What is Julia lang good for?&quot;</span>; api_kwargs=(; url=<span class=hljs-string >&quot;http://127.0.0.1:10897/v1&quot;</span>))</code></pre> <p>It may take a few seconds...</p> <pre><code class="plaintext hljs">[ Info: Tokens: 97 in 19.2 seconds
AIMessage(&quot;Julia is a high-level, high performance dynamic programming language for numerical computing. It provides an ecosystem of open source tools built by the community.&quot;)</code></pre> <p>The above code snippet allows you to download and run a massive 70 billion-parameter model right on your machine with just ~20GB of memory requirement &#40;it&#39;s slightly more than that but not 200GB like the original model&#41;. </p> <h2 id=try_the_rocket_model ><a href="#try_the_rocket_model" class=header-anchor >Try the Rocket model</a></h2> <p>If a 20GB model seems overkill for your needs, try the <a href="https://huggingface.co/pansophic/rocket-3B">Rocket model</a>, which is less than 1GB in size but still boasts 3 billion parameters.</p> <pre><code class="julia hljs"><span class=hljs-comment ># Download the Rocket model and start your server</span>
url = <span class=hljs-string >&quot;https://huggingface.co/ikawrakow/various-2bit-sota-gguf/resolve/main/rocket-3b-2.76bpw.gguf&quot;</span>
model = download_model(url) <span class=hljs-comment ># 1GB download</span>
Llama.run_server(; model)</code></pre> <p>In a separate Julia session, call the model with PromptingTools.jl</p> <pre><code class="julia hljs"><span class=hljs-comment ># In a separate Julia session, call the model with PromptingTools.jl</span>
<span class=hljs-keyword >using</span> PromptingTools
<span class=hljs-keyword >const</span> PT = PromptingTools
<span class=hljs-comment ># PT.register_model!(; name=&quot;llama70b&quot;, schema=PT.CustomOpenAISchema())</span>

msg = aigenerate(PT.CustomOpenAISchema(), <span class=hljs-string >&quot;Say hi!&quot;</span>; api_kwargs=(; url=<span class=hljs-string >&quot;http://127.0.0.1:10897/v1&quot;</span>))
<span class=hljs-comment ># [ Info: Tokens: 75 in 5.9 seconds</span>
<span class=hljs-comment ># AIMessage(&quot;Hello there! I&#x27;m glad you reached out to me. I&#x27;ll do my best to be a helpful AI assistant, so if you have any questions or need assistance with anything, just let me know and I&#x27;d be happy to help. Hi there!&quot;)</span>

msg = aigenerate(PT.CustomOpenAISchema(), <span class=hljs-string >&quot;What is Julia lang good for?&quot;</span>; api_kwargs=(; url=<span class=hljs-string >&quot;http://127.0.0.1:10897/v1&quot;</span>, max_tokens=<span class=hljs-number >2000</span>))
<span class=hljs-comment ># [ Info: Tokens: 137 in 12.6 seconds</span>
<span class=hljs-comment ># AIMessage(&quot;Julia is a high-performance, open-source numerical computing language designed for scientific and engineering applications. It offers fast and efficient computation capabilities with features like multi-threading, automatic array memory optimization, and built-in support for popular libraries such as NumPy, Pandas, and Matplotlib. Julia has gained popularity among data scientists, engineers, and researchers due to its speed, scalability, and ease of use. It is particularly useful when you need to perform complex computations with large datasets or handle high-dimensional arrays efficiently.&quot;)</span></code></pre> <h2 id=conclusion ><a href="#conclusion" class=header-anchor >Conclusion</a></h2> <p>As you can see, the responses are impressive for a 1GB model&#33; It’s truly remarkable how the open-source scene is rapidly advancing, making powerful AI tools accessible to more and more people.</p> <p>This exploration into running large language models locally is just a glimpse into the potential of AI and how it&#39;s being democratized. It&#39;s a testament to the power of open-source software and the continuous innovation in the field of AI and data science. Stay tuned for more amazing developments&#33;</p> <p>PS: Yes, we do need a nicer integration between PromptingTools.jl and Llama.jl. I&#39;m already working on it. Stay tuned&#33;</p> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Jan Siml. Last modified: November 17, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div></div> <footer class=container > <p class=float-end ><a href="#">Back to top</a></p> <div class=footer-icons > <ul class=social-icons > <li><strong>Follow:</strong> <li><a href="https://github.com/svilupp" rel="nofollow noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width=16  height=16  fill=currentColor  class="bi bi-github" viewBox="0 0 16 16"> <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/> </svg> GitHub</a> </ul> </div> <p class=copyright >&copy; 2023- Company, Inc. · <a href="#">Privacy</a> · <a href="#">Terms</a></p> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js" integrity=sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm  crossorigin=anonymous ></script> <script src="/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script> <script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>