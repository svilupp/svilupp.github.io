<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <!-- bootstrap@5.3.1 and bootstrap icon@1.10--> <!-- <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel=stylesheet  integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin=anonymous >--> <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css"> <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/@docsearch/css@3"> <link data-n-head=ssr  rel=stylesheet  href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700,900|Material+Icons"> <link rel=stylesheet  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin=anonymous  referrerpolicy=no-referrer  /> <link rel=stylesheet  href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha512-NhSC1YmyruXifcj/KFRWoC561YpHpc5Jtzgvbuzx5VozKpWvQ+4nXhPdFgmx8xqexRcpAglTj9sIBWINXa8x5w==" crossorigin=anonymous  referrerpolicy=no-referrer  /> <!-- favicon generated through https://realfavicongenerator.net/--> <script src="https://cdn.tailwindcss.com"></script> <link rel=stylesheet  href="/css/franklin.css"> <link rel=apple-touch-icon  sizes=180x180  href="/assets/icon/apple-touch-icon.png"> <link rel=icon  type="image/png" sizes=32x32  href="/assets/icon/favicon-32x32.png"> <link rel=icon  type="image/png" sizes=16x16  href="/assets/icon/favicon-16x16.png"> <link rel=manifest  href="/assets/icon/site.webmanifest"> <link rel=mask-icon  href="/assets/icon/safari-pinned-tab.svg" color="#5bbad5"> <meta name=msapplication-TileColor  content="#da532c"> <meta name=theme-color  content="#ffffff"> <link rel=stylesheet  href="/_css/custom.css"> <title>Automatically Saving Conversations with PromptingTools.jl and AIHelpMe.jl</title> <!-- {{ispage /jan/index.html}} {{insert head_tailwind.html}} {{end}} {{ispage /index.html}} {{insert head_tailwind.html}} {{end}} {{ispage /jan/wip.html}} {{insert head_tailwind.html}} {{end}} {{ispage /jan/scratchpad/index.html}} {{insert head_tailwind.html}} {{end}} --> <header class=dark > <nav class="bg-gray-800 fixed w-full z-50"> <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"> <div class="flex items-center justify-between h-16"> <div class="flex items-center flex-1"> <a href="/" class="flex items-center text-white"> <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill=none  viewBox="0 0 16 16" stroke=currentColor > <path d="M5 10.5a.5.5 0 0 1 .5-.5h2a.5.5 0 0 1 0 1h-2a.5.5 0 0 1-.5-.5zm0-2a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5zm0-2a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5zm0-2a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5z"/> <path d="M3 0h10a2 2 0 0 1 2 2v12a2 2 0 0 1-2 2H3a2 2 0 0 1-2-2v-1h1v1a1 1 0 0 0 1 1h10a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1H3a1 1 0 0 0-1 1v1H1V2a2 2 0 0 1 2-2z"/> <path d="M1 5v-.5a.5.5 0 0 1 1 0V5h.5a.5.5 0 0 1 0 1h-2a.5.5 0 0 1 0-1H1zm0 3v-.5a.5.5 0 0 1 1 0V8h.5a.5.5 0 0 1 0 1h-2a.5.5 0 0 1 0-1H1zm0 3v-.5a.5.5 0 0 1 1 0v.5h.5a.5.5 0 0 1 0 1h-2a.5.5 0 0 1 0-1H1z"/> </svg> <strong>siml.earth</strong> </a> <div class="hidden md:block ml-6"> <div class="flex items-center space-x-4"> <div class="relative group"> <button class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium"> Sites </button> <div class="hidden group-hover:block absolute z-50 mt-2 w-48 rounded-md shadow-lg bg-white ring-1 ring-black ring-opacity-5 before:content-[''] before:absolute before:top-[-10px] before:left-0 before:w-full before:h-[10px]"> <div class=py-1 > <div class="px-4 py-2 text-sm text-gray-700">Choose a Site</div> <a href="/jan/" class="block px-4 py-2 text-sm text-gray-700 hover:bg-gray-100">Jan's Site</a> <a href="/ann/" class="block px-4 py-2 text-sm text-gray-700 hover:bg-gray-100">Ann's Site</a> </div> </div> </div> <div class="border-l border-gray-700 h-6"></div> <span class="text-gray-300 font-bold">Jan's:</span> <a href="/jan/" class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm">Home</a> <a href="/jan/scratchpad/" class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm">Posts</a> <a href="/jan/wip/" class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm">Work in Progress</a> <a href="/jan/about/" class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm">About</a> <a href="/jan/tags/" class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm">Tags</a> <a href="/jan/privacy_policy/" class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm">Privacy Policy</a> <a href="/jan/cookie_policy/" class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm">Cookie Policy</a> </div> </div> </div> <button type=button  class="md:hidden bg-gray-800 inline-flex items-center justify-center p-2 rounded-md text-gray-400 hover:text-white hover:bg-gray-700 focus:outline-none" aria-controls=mobile-menu  aria-expanded=false > <span class=sr-only >Open main menu</span> <svg class="h-6 w-6" fill=none  viewBox="0 0 24 24" stroke=currentColor > <path stroke-linecap=round  stroke-linejoin=round  stroke-width=2  d="M4 6h16M4 12h16M4 18h16" /> </svg> </button> </div> </div> <div class="md:hidden hidden" id=mobile-menu > <div class="px-2 pt-2 pb-3 space-y-1 sm:px-3"> <a href="/jan/" class="text-gray-300 hover:bg-gray-700 hover:text-white block px-3 py-2 rounded-md text-base font-medium">Jan's Site</a> <a href="/ann/" class="text-gray-300 hover:bg-gray-700 hover:text-white block px-3 py-2 rounded-md text-base font-medium">Ann's Site</a> <div class="border-t border-gray-700 my-2"></div> <span class="text-gray-300 font-bold px-3">Jan's:</span> <a href="/jan/" class="text-gray-300 hover:bg-gray-700 hover:text-white block px-3 py-2 rounded-md text-base">Home</a> <a href="/jan/scratchpad/" class="text-gray-300 hover:bg-gray-700 hover:text-white block px-3 py-2 rounded-md text-base">Posts</a> <a href="/jan/wip/" class="text-gray-300 hover:bg-gray-700 hover:text-white block px-3 py-2 rounded-md text-base">Work in Progress</a> <a href="/jan/about/" class="text-gray-300 hover:bg-gray-700 hover:text-white block px-3 py-2 rounded-md text-base">About</a> <a href="/jan/tags/" class="text-gray-300 hover:bg-gray-700 hover:text-white block px-3 py-2 rounded-md text-base">Tags</a> <a href="/jan/privacy_policy/" class="text-gray-300 hover:bg-gray-700 hover:text-white block px-3 py-2 rounded-md text-base">Privacy Policy</a> <a href="/jan/cookie_policy/" class="text-gray-300 hover:bg-gray-700 hover:text-white block px-3 py-2 rounded-md text-base">Cookie Policy</a> </div> </div> </nav> </header> <div class="container px-3 mx-auto pt-20"> <div class="max-w-4xl mx-auto"> <h1 class="text-4xl font-bold mb-4 text-center">Automatically Saving Conversations with PromptingTools.jl and AIHelpMe.jl</h1> <p class="text-gray-600 mb-8 text-center">25 April 2024</p> </div> <div class=franklin-content ><h1 id=tldr ><a href="#tldr" class=header-anchor >TL;DR</a></h1> <p>Learn how to automatically save conversations with PromptingTools.jl. By saving conversations, you can contribute to building a dataset for fine-tuning a Julia-specific language model. This tutorial provides code examples to get you started</p> <p><div class=franklin-toc ><ol><li><a href="#tldr">TL;DR</a><ol><li><a href="#introduction">Introduction</a><li><a href="#defining_a_custom_schema_for_saving_conversations">Defining a Custom Schema for Saving Conversations</a><ol><li><a href="#example_1_saving_conversations_with_aigenerate">Example 1: Saving Conversations with <code>aigenerate</code></a></ol><li><a href="#example_2_registering_a_traced_model">Example 2: Registering a Traced Model</a><li><a href="#loading_conversations">Loading Conversations</a><li><a href="#exporting_conversations_in_sharegpt_format">Exporting Conversations in ShareGPT Format</a><li><a href="#saving_aihelpme_conversations">Saving AIHelpMe Conversations</a><li><a href="#sharing_the_conversations">Sharing The Conversations</a><li><a href="#conclusion">Conclusion</a></ol></ol></div> </p> <h2 id=introduction ><a href="#introduction" class=header-anchor >Introduction</a></h2> <p>Recently, there have been exciting discussions about fine-tuning a language model for the Julia programming language &#40;see <a href="https://discourse.julialang.org/t/an-llm-fine-tuned-for-julia-call-for-comments-help/113462/8">here</a>&#41;. </p> <p>As part of this effort, we need a high-quality dataset of GOOD conversations related to Julia. One way to contribute to this effort is to start logging conversations with Large Language Models &#40;LLMs&#41; that are relevant to Julia. </p> <p>In this blog post, we will explore how to automatically save conversations using PromptingTools.jl and AIHelpMe.jl, a powerful Julia package for interacting with language models. By saving these conversations, we can build a valuable dataset for fine-tuning a Julia-specific language model.</p> <h2 id=defining_a_custom_schema_for_saving_conversations ><a href="#defining_a_custom_schema_for_saving_conversations" class=header-anchor >Defining a Custom Schema for Saving Conversations</a></h2> <p>A lesser-known feature, PromptingTools has a custom callback system that allows us to define custom schemas that will then call your arbitrary functions before and after each LLM call &#40;it&#39;s used mostly for observability&#41;.</p> <p>To save conversations, we need to define a custom schema that wraps our normal prompt schema. We can do this by creating a new struct <code>SaverSchema</code> that inherits from <code>PT.AbstractTracerSchema</code>.</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> Dates
<span class=hljs-keyword >using</span> JSON3
<span class=hljs-keyword >using</span> PromptingTools
<span class=hljs-keyword >const</span> PT = PromptingTools

<span class=hljs-keyword >const</span> SAVE_DIR = <span class=hljs-string >&quot;finetune_julia&quot;</span>

<span class=hljs-meta >@kwdef</span> <span class=hljs-keyword >struct</span> SaverSchema &lt;: PT.AbstractTracerSchema
    schema::PT.AbstractPromptSchema
<span class=hljs-keyword >end</span></code></pre> <p>Any call to this schema triggers a call to function <code>initialize_tracer</code> before the LLM call and to <code>finalize_tracer</code> after the LLM call.</p> <p>In our case, we want to overload the <code>finalize_tracer</code> function to save the conversation after the LLM call.</p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> PT.finalize_tracer(
    tracer_schema::SaverSchema, 
    tracer, 
    msg_or_conv; 
    tracer_kwargs=<span class=hljs-built_in >NamedTuple</span>(), 
    model=<span class=hljs-string >&quot;&quot;</span>, 
    kwargs...
)
    <span class=hljs-comment ># We already captured all kwargs, they are already in `tracer`, we can ignore tracer_kwargs in this implementation</span>

    time_received = Dates.format(now(), <span class=hljs-string >&quot;YYYYmmdd_HHMMSS&quot;</span>)
    path = joinpath(SAVE_DIR, <span class=hljs-string >&quot;conversation__<span class=hljs-subst >$(model)</span>__<span class=hljs-subst >$(time_received)</span>.json&quot;</span>)
    conv = msg_or_conv <span class=hljs-keyword >isa</span> <span class=hljs-built_in >AbstractVector</span> ? msg_or_conv : [msg_or_conv]
    PT.save_conversation(path, conv)

    <span class=hljs-keyword >return</span> msg_or_conv
<span class=hljs-keyword >end</span></code></pre> <h3 id=example_1_saving_conversations_with_aigenerate ><a href="#example_1_saving_conversations_with_aigenerate" class=header-anchor >Example 1: Saving Conversations with <code>aigenerate</code></a></h3> <p>Now that we have defined our custom schema, we can use it to save conversations with <code>aigenerate</code>. We need to explicitly provide the <code>SaverSchema</code> instance to <code>aigenerate</code> along with the input prompt.</p> <pre><code class="julia hljs">schema = SaverSchema(PT.OpenAISchema())
msg = aigenerate(schema, <span class=hljs-string >&quot;Say hi&quot;</span>, model=<span class=hljs-string >&quot;gpt3t&quot;</span>, return_all=<span class=hljs-literal >true</span>)</code></pre> <p>When you call this function, it will save the conversation to the folder defined in <code>SAVE_DIR</code>.</p> <p>One gotcha, if you send multiple messages in the save convo, is that all turns will be saved in separate files. The easiest way would be to ignore it and solve it in post-processing &#40;<code>AIMessage</code> have unique IDs so it should be easy to detect&#41; Alternatively, you can save the hash of the content of the first 2-3 messages in the filename to clearly see the continued conversations.</p> <h3 id=example_2_registering_a_traced_model ><a href="#example_2_registering_a_traced_model" class=header-anchor >Example 2: Registering a Traced Model</a></h3> <p>Instead of providing the custom schema every time, we can register a traced model with the custom schema. This way, we can use the model name instead of the schema instance.</p> <pre><code class="julia hljs"><span class=hljs-comment ># Overwrite the schema for this model and define a nice alias</span>
PT.register_model!(; name=<span class=hljs-string >&quot;gpt-3.5-turbo&quot;</span>, schema)
PT.MODEL_ALIASES[<span class=hljs-string >&quot;gpt3t&quot;</span>] = <span class=hljs-string >&quot;gpt-3.5-turbo&quot;</span>

<span class=hljs-comment ># Notice the return_all -&gt; we need to return ALL messages, it would be a useless record otherwise</span>
msg = aigenerate(<span class=hljs-string >&quot;Say hi&quot;</span>, model=<span class=hljs-string >&quot;gpt3t&quot;</span>, return_all=<span class=hljs-literal >true</span>)</code></pre> <p>Conversation gets saved.</p> <h3 id=loading_conversations ><a href="#loading_conversations" class=header-anchor >Loading Conversations</a></h3> <p>Once we have saved conversations, we can load them back into Julia using <code>load_conversation</code>.</p> <pre><code class="julia hljs">conv = PT.load_conversation(<span class=hljs-string >&quot;finetune_julia/conversation__gpt3t__20240425_205853.json&quot;</span>)</code></pre>
<h3 id=exporting_conversations_in_sharegpt_format ><a href="#exporting_conversations_in_sharegpt_format" class=header-anchor >Exporting Conversations in ShareGPT Format</a></h3>
<p>Once we have enough conversation, we will want to export so our finetuning tool can use them.  I would highly recommend Axolotl &#40;see an example from <a href="https://github.com/svilupp/Julia-LLM-Leaderboard/blob/main/experiments/cheater-7b-finetune/lora.yml">my finetune</a>&#41;. </p>
<p>Axolotl can work with instructions &#40;conversations&#41; in ShareGPT format. This is how you can export multiple conversations into the required JSONL file:</p>
<pre><code class="julia hljs">conv1 = [PT.SystemMessage(<span class=hljs-string >&quot;System message 1&quot;</span>), 
         PT.UserMessage(<span class=hljs-string >&quot;User message&quot;</span>), 
         PT.AIMessage(<span class=hljs-string >&quot;AI message&quot;</span>)]
conv2 = [PT.SystemMessage(<span class=hljs-string >&quot;System message 2&quot;</span>), 
         PT.UserMessage(<span class=hljs-string >&quot;User message&quot;</span>), 
         PT.AIMessage(<span class=hljs-string >&quot;AI message&quot;</span>)]
path = joinpath(<span class=hljs-string >&quot;finetune_julia&quot;</span>, <span class=hljs-string >&quot;export_sharegpt.jsonl&quot;</span>)
PT.save_conversations(path, [conv1, conv2])</code></pre>
<h2 id=saving_aihelpme_conversations ><a href="#saving_aihelpme_conversations" class=header-anchor >Saving AIHelpMe Conversations</a></h2>
<p>If you use AIHelpMe, you&#39;re also generating loads of interesting data&#33; The simplest thing for auto-logging your questions is to wrap the entry function <code>aihelp</code> and serialize the whole <code>RAGResult</code> &#40;it has all the diagnostics and underlying information&#41;</p>
<pre><code class="julia hljs"><span class=hljs-keyword >function</span> aih(question; kwargs...)
    result = aihelp(question; return_all=<span class=hljs-literal >true</span>, kwargs...)
    dt = Dates.format(now(), <span class=hljs-string >&quot;YYYYmmdd_HHMMSS&quot;</span>)
    JSON3.write(joinpath(SAVE_DIR, <span class=hljs-string >&quot;aihelp__<span class=hljs-subst >$(dt)</span>.json&quot;</span>), result)
    <span class=hljs-keyword >return</span> result
<span class=hljs-keyword >end</span></code></pre>
<p>To use it, you would replace <code>aihelp&#40;&quot;some question...&quot;&#41;</code> with <code>aih&#40;&quot;some question...&quot;&#41;</code>.</p>
<p>The serialized RAGResult is c. 200kB, but it provides a lot of helpful detail about your question. If you want to save space, save just the individual conversations in <code>result.conversations</code>.</p>
<h2 id=sharing_the_conversations ><a href="#sharing_the_conversations" class=header-anchor >Sharing The Conversations</a></h2>
<p>Where to share these? To be discussed. Come join us on <a href="https://discourse.julialang.org/t/an-llm-fine-tuned-for-julia-call-for-comments-help/113462/8">Discourse</a> or on Julia Slack in #generative-ai.</p>
<h2 id=conclusion ><a href="#conclusion" class=header-anchor >Conclusion</a></h2>
<p>In this blog post, we have seen how to automatically save conversations using PromptingTools.jl. By defining a custom schema and overloading the <code>finalize_tracer</code> function, we can save conversations to files. We can also register a traced model and use it to generate text. Finally, we can load and export conversations in ShareGPT format for finetuning. With AIHelpMe.jl, we can serialize the whole <code>RAGResult</code> with JSON3.</p>
<div class=page-foot >
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Jan Siml. Last modified: December 11, 2024.
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia asdasdas programming language</a>.
</div>
</div></div> 

<footer class="container mx-auto px-4 py-4 border-t">
  
  <p class="text-right mb-3">
    <a href="#" class="text-gray-600 hover:text-gray-900 transition-colors">Back to top</a>
  </p>
  
  
  <div class="flex flex-col items-center justify-center space-y-3">
    
    <div class=footer-icons >
      <ul class="flex items-center space-x-4">
        <li class="text-gray-700 font-medium">Follow:
        <li>
          <a href="https://github.com/svilupp" class="flex items-center space-x-2 text-gray-600 hover:text-gray-900 transition-colors" rel="nofollow noopener noreferrer">
            <svg xmlns="http://www.w3.org/2000/svg" width=20  height=20  fill=currentColor  class="bi bi-github" viewBox="0 0 16 16">
              <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
            </svg>
            <span>GitHub</span>
          </a>
        
      </ul>
    </div>

    
    <p class="text-sm text-gray-600">
      &copy; 2024 · 
      <a href="#" class="hover:text-gray-900 transition-colors">Privacy</a> · 
      <a href="#" class="hover:text-gray-900 transition-colors">Terms</a>
    </p>
  </div>
</footer>





  <script src="/libs/highlight/highlight.min.js"></script>
<script>hljs.highlightAll();hljs.configure({tabReplace: '    '});</script>


<script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>
<script>
  // Mobile menu toggle
  const mobileMenuButton = document.querySelector('[aria-controls="mobile-menu"]');
  const mobileMenu = document.getElementById('mobile-menu');

  mobileMenuButton.addEventListener('click', () => {
    const expanded = mobileMenuButton.getAttribute('aria-expanded') === 'true';
    mobileMenuButton.setAttribute('aria-expanded', !expanded);
    mobileMenu.classList.toggle('hidden');
  });
</script>